# BackPropogation
A technique to update the weights in a multi-layer neural network. The weights are updated proportional to the impact they have on the output.
# About
The example is written on a random sequence function. The weights should predict using back propogation based on linear and logsigmoid transfer functions.
